package logic;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;

public class ANN {
	
	//TODO: Activation threshold, possible bias, range of weights
	private Settings set;
	
	private Double[] in;
	private Double[] out;
	
	//Layout of ANN: # of neurons in each layer
	private int[] layout;
	private List<double[][]> weights;

	public ANN(List<Double> pheno, Settings set) {		
		//System.out.println("Ran ANN constructor");
		
		this.set = set;
		this.layout = set.getLayout();
		
		/*
		for (int i=0; i<pheno.size(); i++) {
			pheno.set(i, Algorithms.remap(pheno.get(i), 0, 1, -2, 2));
			if (pheno.get(i) > 2 || pheno.get(i) < -2) {
				System.err.println("Scale failed");
				System.out.println(pheno.get(i));
			}
		}
		*/
		
		//Initialize ANN with phenotype weights
		
		weights = initializeWeights();
		
		//System.out.println("Ran ANN initializeWeights");
		
		//System.out.println(pheno);
		
		Iterator<Double> iter = pheno.iterator();
		for (int i=0; i<layout.length-1; i++) {			
			for (int j=0; j<layout[i]; j++) {
				for (int k=0; k<layout[i+1]; k++) {
					double temp = iter.next().doubleValue();
					//weights are stored in double[][]
					weights.get(i)[j][k] = temp;
				}			
			}
		}
		
		//System.out.println("Ran ANN initialization");
		
	}
	
	private List<double[][]> initializeWeights() {
		List<double[][]> out = new ArrayList<double[][]>();
		for (int i=0; i<layout.length-1; i++) {
			double[][] layerWeights = new double[layout[i]][layout[i+1]];
			out.add(layerWeights);
		}
		return out;
	}
		
	/*
	 * @param sensorInputs
	 * list of in this case 6 doubles, representing what is seen by sensor in directions
	 * food: forward, left, right
	 * poison: forward, left, right	 * 
	 */
	
	public String chooseDirection(Double[] sensorInputs) {
		in = sensorInputs;
		//To get a value when all sensors are 0
		in[0] += 0.1;
		List<Double> out = new ArrayList<Double>();
		List<Double> next = new ArrayList<Double>();
		
		/*
		List<double[][]> scaledWeights = initializeWeights();
		
		for (int i=0; i<layout.length-1; i++) {
			for (int j=0; j<layout[i]; j++) {
				for (int k=0; k<layout[i+1]; k++) {
					scaledWeights.get(i)[j][k] = SupportAlgs.scale(weights.get(i)[j][k], 0, Math.pow(2.0, set.getBitSize()), -2.0, 2.0);
				}
			}
		}
		*/
		
		for (int i=0; i<layout.length-1; i++) {
			next.addAll(Collections.nCopies(layout[i+1], 0.0));
			
			if (i==0) { out = Arrays.asList(in); }
			
			for (int j=0; j<layout[i]; j++) {
				for (int k=0; k<layout[i+1]; k++) {
					
					if (i < layout.length-2) {
						Double neuronInput = next.get(k)+out.get(j)*weights.get(i)[j][k];
						double sigmoid = sigmoid(neuronInput);
						if (sigmoid > 0.501) {
							next.set(k, sigmoid);																	
						} else {
							next.set(k,  0.0);
						}
					} else {
						next.set(k, next.get(k)+out.get(j)*weights.get(i)[j][k]);	
					}
				}			
			}
			out = next;
		}
		
		if (out.get(0) < 0.5 && out.get(1) < 0.5 && out.get(2) < 0.5) {
			return "";
		}
		
		
		if (out.get(0) > out.get(1) && out.get(0) > out.get(2)) {
			return "forward";
		} else if (out.get(1) > out.get(0) && out.get(1) > out.get(2)) {
			return "left";
		} else if (out.get(2) > out.get(0) && out.get(2) > out.get(1)) {
			return "right";
		} else {
			return "";
		}
	}
	
	private double sigmoid(double x) {
		return 1/(1 + Math.exp(-x));
	}
	
	public static void main(String[] args) {
		
		double[] ints = new double[] {0.509553557573525, 0.3072429076819545, 0.6989591264436463, 0.5972541484342172, 0.38295041086723813, 0.5402855948926151, 0.4574858609185918, 0.62484308605748, 0.5600028280575721, 0.46245047399886086, 0.19647879386984546, 0.6574404461136687, 0.7426916431606482, 0.5035482251465555, 0.7910964068880773, 0.0043246366771145794, 0.1725436884739604, 0.20060258980644263, 0.6050947791113753, 0.3473181915774215, 0.9682773289322323, 0.7924648347461145, 0.9017059312491944, 0.0420320091576728, 0.28189183533224904, 0.19750213958428786, 0.547940580508284, 0.3923391320918067, 0.5915103022662493, 0.020828491112443448, 0.4679393280458376, 0.11735122266841258, 0.9459235610841028, 0.08780273856329845, 0.9330773217929703, 0.6976721729861183, 0.4519562194129305, 0.5602072840064736, 0.0570533048340206, 0.3651907707929949, 0.16523611456105947, 0.2209713425821238, 0.932587832061342, 0.5914857453103981, 0.2958800750749153, 0.7528622404328718, 0.981456069309066, 0.8622272261957131, 0.6758745155350686, 0.4038442808287468, 0.0562842081316729, 0.8580433942041354, 0.6944754910103957, 0.7943221673916233, 0.26576162157506145, 0.22303308732462246, 0.14434764877428485, 0.04974932878429028, 0.4635312019059291, 0.5966308954600206, 0.6737043693294932, 0.10032871187591508, 0.6433650316026789, 0.8633146933081788, 0.3506680483153818, 0.9483988798096767, 0.15160083895230492, 0.3049001047354416, 0.7872096320274783, 0.43907604466438055, 0.6546666702234899, 0.6157144634124254, 0.12965488745036846, 0.3046548847118793, 0.34137371852791387, 0.6840515570742716, 0.04155423114052281, 0.020682494930382656, 0.00997936907001884, 0.8130520850638486, 0.4831576051004832, 0.5642542804562846, 0.36432323304298475, 0.008675552690863508, 0.8847604458635877, 0.8357515603585634, 0.3819818504232435, 0.04940844737702099, 0.8023975916521807, 0.2659018696841612, 0.567582817059563, 0.5060199689001983, 0.7257185235859248, 0.4777501657395963, 0.010864643899266668, 0.26409518684605227, 0.5674366623751802, 0.13541874381914054, 0.4755119981984496, 0.3406369690819764, 0.3135578531497828, 0.2467414308450605, 0.8137555068149265, 0.2308474414734818, 0.12436826078990848, 0.30609150452856504, 0.8018712286619308, 0.005585055559698682, 0.8539090558680063, 0.5725411789705983, 0.7732588769731912, 0.5706538491660177, 0.7592070187961993, 0.7102251749082058, 0.5816502733599888, 0.29596742075802485, 0.9426210667793737, 0.777987480738282, 0.3746400845232589, 0.2924486029343695, 0.40598588422364545, 0.25518106302141275, 0.8452893370473182, 0.2905880315641499, 0.6300734286640102, 0.3881967469514511, 0.1111860516533727, 0.8568981062299799, 0.3981680830165898, 0.6471806206316327, 0.20163260899681668, 0.01750664712564587, 0.3284035968372965, 0.4935320149599213, 0.3272733334311424, 0.5389491177979711, 0.8800179427421387, 0.6536148180619237, 0.928111315416375, 0.422379232751808, 0.9391294947677019, 0.039409879181607876, 0.2647752705307679, 0.296794965115897, 0.29755034655202117, 0.8018587369128193, 0.6924386921362461, 0.7993048076486577, 0.7508030279170824, 0.5864260257678648, 0.4430234300000456, 0.3859908852348617, 0.9859704216891676, 0.5902383749811746, 0.6628239309476052, 0.6659215039573332, 0.40230333319945544, 0.5483704425862476, 0.04501661795946876, 0.840534383614761, 0.27759897476408324, 0.2612490668719766, 0.850624695142415, 0.848931609181268, 0.9287960693486884, 0.9020516022996734, 0.4992431611533503, 0.3590970629196747, 0.35701360689792805, 0.9950269596921519, 0.5485246180237865, 0.28845655512162705, 0.5503966592071106, 0.41390519312975416, 0.6753708664585241, 0.5669597556097836, 0.20212829652487874, 0.18488837130699043, 0.22197185884314896, 0.5205344070112699, 0.4487664766300551, 0.6038761381662869, 0.7308356690388594, 0.26110599817598046, 0.08108534366251652, 0.38911345728893254, 0.11918448684736449, 0.3816667017488101, 0.03393452803746766, 0.4049208301614743, 0.02747448439307343, 0.7082439633758159, 0.2983844471089929, 0.6578497579862499, 0.7009817084607495, 0.5226529675175222, 0.5754285243322256, 0.7922952084437213, 0.2993923843049632, 0.2353824577581558, 0.6078411416964746, 0.023409364499423435, 0.7161069008814425, 0.917780024379569, 0.9640899116794136, 0.05697089988371007, 0.9116810382950865, 0.5577379566053651, 0.5939952474568165, 0.16284604257605195, 0.26887545972043025, 0.9103962422935805, 0.4079861621673673, 0.885227687188335, 0.6413926294021126, 0.9666039477748898, 0.9247895951800971, 0.5691705995425986, 0.5340061557328847, 0.010906329539511761, 0.5552060020649643, 0.5538776606160174, 0.26704001253035803, 0.7301605642682437, 0.5511997444897712, 0.44125203325807705, 0.8933048567202467, 0.6118666231810942, 0.4373838791153527, 0.25228660855225116, 0.9214708235111423, 0.13190333689682554, 0.9829663398925436, 0.44577003514652713, 0.010511123207448403, 0.8023154351643377, 0.45838515085817977, 0.5427959664975743, 0.4745064496646253, 0.2089808971528373, 0.7067641468910559, 0.4417369511809206, 0.8362876215677656, 0.5078142012838062, 0.19377373182332291, 0.11467896409446954, 0.13787705204866108, 0.8533806367157326, 0.5994816569659166, 0.9083260374246542, 0.4226367581301197, 0.3495818492558983, 0.6128994100054889, 0.9552267044564973, 0.5734133869177985, 0.08073598694549067, 0.33676153021905997, 0.0847574040236988, 0.21999803019190134, 0.31154583162032634, 0.8228237137168213, 0.9581782358302486, 0.6668782394946278, 0.11760721091051107, 0.02093483683956776, 0.0036577257964856003, 0.9190788449863792, 0.4301446221393206, 0.04610423282202902, 0.6845728757614343};
		
		List<Double> pheno = new ArrayList<Double>(ints.length);
		
		for (double i : ints) {
			pheno.add(i);
		}
		
		Settings set = new Settings();
		
		ANN ann = new ANN(pheno, set);
		
		System.out.println("Finished");
		
	}
	
	

}
